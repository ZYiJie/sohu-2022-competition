{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a551c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import json\n",
    "import math\n",
    "import copy\n",
    "import os, sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from scipy.special import softmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31588b5d",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781faac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './data/rec_data/train-dataset.csv'\n",
    "# # path = './data/rec_data/test-dataset.csv'\n",
    "# data = pd.read_csv(path)\n",
    "# data['time'] = pd.to_datetime(data['logTs'],unit='ms',origin=pd.to_datetime('1970-01-01 08:00:00'))\n",
    "# data['Hour'] = data['time'].dt.hour\n",
    "# data['Min'] = data['time'].dt.hour*60+data['time'].dt.minute\n",
    "# data['seq'] = data['userSeq'].str.split('[;:]').fillna(0)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e5f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv('./data/rec_data/train-co-occurrence-feature.csv')\n",
    "# df2 = pd.read_csv('./data/rec_data/train-itemId-feature.csv')\n",
    "# df3 = pd.read_csv('./data/rec_data/train-emotion-feature.csv')\n",
    "\n",
    "# train_all_feature = pd.concat([data,df1,df2,df3],axis=1)\n",
    "# del train_all_feature['seqLen']\n",
    "# train_all_feature['seqLen'] = train_all_feature['userSeq'].str.count(';').fillna(0).astype('int')\n",
    "# del train_all_feature['userSeq']\n",
    "\n",
    "# print(train_all_feature.columns)\n",
    "# train_all_feature.to_csv('./data/feature/train_all_feature.csv', index=False)\n",
    "# train_all_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9404f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './data/rec_data/test-dataset.csv'\n",
    "\n",
    "# data = pd.read_csv(path)\n",
    "# data['time'] = pd.to_datetime(data['logTs'],unit='ms',origin=pd.to_datetime('1970-01-01 08:00:00'))\n",
    "# data['Hour'] = data['time'].dt.hour\n",
    "# data['Min'] = data['time'].dt.hour*60+data['time'].dt.minute\n",
    "# data['seq'] = data['userSeq'].str.split('[;:]').fillna(0)\n",
    "\n",
    "# df1 = pd.read_csv('./data/rec_data/test-co-occurrence-feature.csv')\n",
    "# df2 = pd.read_csv('./data/rec_data/test-itemId-feature.csv')\n",
    "# df3 = pd.read_csv('./data/rec_data/test-emotion-feature.csv')\n",
    "\n",
    "# test_all_feature = pd.concat([data,df1,df2,df3],axis=1)\n",
    "# del test_all_feature['seqLen']\n",
    "# test_all_feature['seqLen'] = test_all_feature['userSeq'].str.count(';').fillna(0).astype('int')\n",
    "# del test_all_feature['userSeq']\n",
    "\n",
    "# print(test_all_feature.columns)\n",
    "# print(len(test_all_feature))\n",
    "# test_all_feature.to_csv('./data/feature/test_all_feature.csv', index=False)\n",
    "# test_all_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7fe754",
   "metadata": {},
   "source": [
    "#### 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb5ef63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sampleId', 'label', 'pvId', 'suv', 'itemId', 'logTs', 'operator',\n",
      "       'browserType', 'deviceType', 'osType', 'province', 'city', 'time',\n",
      "       'Hour', 'Min', 'seq', 'sum', 'mean', 'std', 'nor_sum', 'nor_mean',\n",
      "       'nor_std', 'posCnt', 'negCnt', 'historyCnt', 'allCnt', 'entity_cnt',\n",
      "       'mean_emotion_gap', 'seqLen'],\n",
      "      dtype='object')\n",
      "5656022\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampleId</th>\n",
       "      <th>label</th>\n",
       "      <th>pvId</th>\n",
       "      <th>suv</th>\n",
       "      <th>itemId</th>\n",
       "      <th>logTs</th>\n",
       "      <th>operator</th>\n",
       "      <th>browserType</th>\n",
       "      <th>deviceType</th>\n",
       "      <th>osType</th>\n",
       "      <th>...</th>\n",
       "      <th>nor_sum</th>\n",
       "      <th>nor_mean</th>\n",
       "      <th>nor_std</th>\n",
       "      <th>posCnt</th>\n",
       "      <th>negCnt</th>\n",
       "      <th>historyCnt</th>\n",
       "      <th>allCnt</th>\n",
       "      <th>entity_cnt</th>\n",
       "      <th>mean_emotion_gap</th>\n",
       "      <th>seqLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1420332726637uyIZR2O</td>\n",
       "      <td>1581173072343wnwm3q</td>\n",
       "      <td>10092752</td>\n",
       "      <td>1641039890894</td>\n",
       "      <td>2203920</td>\n",
       "      <td>1583865</td>\n",
       "      <td>2326891</td>\n",
       "      <td>3585570</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1076</td>\n",
       "      <td>5732</td>\n",
       "      <td>36535</td>\n",
       "      <td>6808</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1420332726637uyIZR2O</td>\n",
       "      <td>1581173072343wnwm3q</td>\n",
       "      <td>10085565</td>\n",
       "      <td>1641039890894</td>\n",
       "      <td>2203920</td>\n",
       "      <td>1583865</td>\n",
       "      <td>2326891</td>\n",
       "      <td>3585570</td>\n",
       "      <td>...</td>\n",
       "      <td>176</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1392</td>\n",
       "      <td>6463</td>\n",
       "      <td>79661</td>\n",
       "      <td>7855</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1420332726637uyIZR2O</td>\n",
       "      <td>1581173072343wnwm3q</td>\n",
       "      <td>10105937</td>\n",
       "      <td>1641039890894</td>\n",
       "      <td>2203920</td>\n",
       "      <td>1583865</td>\n",
       "      <td>2326891</td>\n",
       "      <td>3585570</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1820</td>\n",
       "      <td>9782</td>\n",
       "      <td>79034</td>\n",
       "      <td>11602</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1420332726637uyIZR2O</td>\n",
       "      <td>1581173072343wnwm3q</td>\n",
       "      <td>10082274</td>\n",
       "      <td>1641039890894</td>\n",
       "      <td>2203920</td>\n",
       "      <td>1583865</td>\n",
       "      <td>2326891</td>\n",
       "      <td>3585570</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1927</td>\n",
       "      <td>9660</td>\n",
       "      <td>47663</td>\n",
       "      <td>11587</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1420332726637uyIZR2O</td>\n",
       "      <td>1581173072343wnwm3q</td>\n",
       "      <td>10083446</td>\n",
       "      <td>1641039890894</td>\n",
       "      <td>2203920</td>\n",
       "      <td>1583865</td>\n",
       "      <td>2326891</td>\n",
       "      <td>3585570</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1607</td>\n",
       "      <td>7436</td>\n",
       "      <td>35258</td>\n",
       "      <td>9043</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233799</th>\n",
       "      <td>4233800</td>\n",
       "      <td>0</td>\n",
       "      <td>1641237780999Vpq1Hnl</td>\n",
       "      <td>1497538865583737</td>\n",
       "      <td>10119437</td>\n",
       "      <td>1641225378200</td>\n",
       "      <td>1570834</td>\n",
       "      <td>1583737</td>\n",
       "      <td>2326891</td>\n",
       "      <td>3585570</td>\n",
       "      <td>...</td>\n",
       "      <td>396</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>1656</td>\n",
       "      <td>5899</td>\n",
       "      <td>47535</td>\n",
       "      <td>7555</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233800</th>\n",
       "      <td>4233801</td>\n",
       "      <td>0</td>\n",
       "      <td>1641237780999Vpq1Hnl</td>\n",
       "      <td>1497538865583737</td>\n",
       "      <td>10123561</td>\n",
       "      <td>1641225390758</td>\n",
       "      <td>1570834</td>\n",
       "      <td>1583737</td>\n",
       "      <td>2326891</td>\n",
       "      <td>3585570</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>90</td>\n",
       "      <td>7122</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233801</th>\n",
       "      <td>4233802</td>\n",
       "      <td>0</td>\n",
       "      <td>1641237780999Vpq1Hnl</td>\n",
       "      <td>1497538865583737</td>\n",
       "      <td>10122359</td>\n",
       "      <td>1641225381972</td>\n",
       "      <td>1570834</td>\n",
       "      <td>1583737</td>\n",
       "      <td>2326891</td>\n",
       "      <td>3585570</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>903</td>\n",
       "      <td>17163</td>\n",
       "      <td>1057</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233802</th>\n",
       "      <td>4233803</td>\n",
       "      <td>0</td>\n",
       "      <td>1641237780999Vpq1Hnl</td>\n",
       "      <td>1497538865583737</td>\n",
       "      <td>10122833</td>\n",
       "      <td>1641225322020</td>\n",
       "      <td>1570834</td>\n",
       "      <td>1583737</td>\n",
       "      <td>2326891</td>\n",
       "      <td>3585570</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>1019</td>\n",
       "      <td>89892</td>\n",
       "      <td>1247</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233803</th>\n",
       "      <td>4233804</td>\n",
       "      <td>0</td>\n",
       "      <td>1641237780999Vpq1Hnl</td>\n",
       "      <td>1497538865583737</td>\n",
       "      <td>10120530</td>\n",
       "      <td>1641225386226</td>\n",
       "      <td>1570834</td>\n",
       "      <td>1583737</td>\n",
       "      <td>2326891</td>\n",
       "      <td>3585570</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2241</td>\n",
       "      <td>9661</td>\n",
       "      <td>56325</td>\n",
       "      <td>11902</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4233804 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sampleId  label                  pvId                  suv    itemId  \\\n",
       "0               1      0  1420332726637uyIZR2O  1581173072343wnwm3q  10092752   \n",
       "1               2      0  1420332726637uyIZR2O  1581173072343wnwm3q  10085565   \n",
       "2               3      0  1420332726637uyIZR2O  1581173072343wnwm3q  10105937   \n",
       "3               4      0  1420332726637uyIZR2O  1581173072343wnwm3q  10082274   \n",
       "4               5      0  1420332726637uyIZR2O  1581173072343wnwm3q  10083446   \n",
       "...           ...    ...                   ...                  ...       ...   \n",
       "4233799   4233800      0  1641237780999Vpq1Hnl     1497538865583737  10119437   \n",
       "4233800   4233801      0  1641237780999Vpq1Hnl     1497538865583737  10123561   \n",
       "4233801   4233802      0  1641237780999Vpq1Hnl     1497538865583737  10122359   \n",
       "4233802   4233803      0  1641237780999Vpq1Hnl     1497538865583737  10122833   \n",
       "4233803   4233804      0  1641237780999Vpq1Hnl     1497538865583737  10120530   \n",
       "\n",
       "                 logTs  operator  browserType  deviceType   osType  ...  \\\n",
       "0        1641039890894   2203920      1583865     2326891  3585570  ...   \n",
       "1        1641039890894   2203920      1583865     2326891  3585570  ...   \n",
       "2        1641039890894   2203920      1583865     2326891  3585570  ...   \n",
       "3        1641039890894   2203920      1583865     2326891  3585570  ...   \n",
       "4        1641039890894   2203920      1583865     2326891  3585570  ...   \n",
       "...                ...       ...          ...         ...      ...  ...   \n",
       "4233799  1641225378200   1570834      1583737     2326891  3585570  ...   \n",
       "4233800  1641225390758   1570834      1583737     2326891  3585570  ...   \n",
       "4233801  1641225381972   1570834      1583737     2326891  3585570  ...   \n",
       "4233802  1641225322020   1570834      1583737     2326891  3585570  ...   \n",
       "4233803  1641225386226   1570834      1583737     2326891  3585570  ...   \n",
       "\n",
       "         nor_sum  nor_mean nor_std  posCnt  negCnt historyCnt  allCnt  \\\n",
       "0              0         0       0    1076    5732      36535    6808   \n",
       "1            176         8      16    1392    6463      79661    7855   \n",
       "2             65         3       8    1820    9782      79034   11602   \n",
       "3            102         4      13    1927    9660      47663   11587   \n",
       "4             18         0       3    1607    7436      35258    9043   \n",
       "...          ...       ...     ...     ...     ...        ...     ...   \n",
       "4233799      396        18      48    1656    5899      47535    7555   \n",
       "4233800        0         0       0      13      90       7122     103   \n",
       "4233801        0         0       0     154     903      17163    1057   \n",
       "4233802        0         0       0     228    1019      89892    1247   \n",
       "4233803        0         0       0    2241    9661      56325   11902   \n",
       "\n",
       "         entity_cnt  mean_emotion_gap  seqLen  \n",
       "0                 0               1.0      20  \n",
       "1                 5               0.0      20  \n",
       "2                 2               0.0      20  \n",
       "3                 3               0.0      20  \n",
       "4                 1               0.0      20  \n",
       "...             ...               ...     ...  \n",
       "4233799           3               0.0      20  \n",
       "4233800           0               1.0      20  \n",
       "4233801           0               1.0      20  \n",
       "4233802           0               1.0      20  \n",
       "4233803           0               1.0      20  \n",
       "\n",
       "[4233804 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './data/feature/train_all_feature.csv'\n",
    "train_feature = pd.read_csv(path)\n",
    "path = './data/feature/test_all_feature.csv'\n",
    "test_feature = pd.read_csv(path)\n",
    "print(train_feature.columns)\n",
    "print(len(train_feature)+len(test_feature))\n",
    "train_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5dc3e",
   "metadata": {},
   "source": [
    "#### 生成词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb84f547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146791\n"
     ]
    }
   ],
   "source": [
    "entity_map = {}\n",
    "with open('./data/rec_data/recommend_content_entity_0317.txt') as f:\n",
    "    for line in f:\n",
    "        if len(line.strip()):\n",
    "            js = json.loads(line)\n",
    "            entity_map[int(js['id'])] = js['entity']\n",
    "print(len(entity_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa436df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureNames = ['itemId', 'province', 'city', 'Hour', 'deviceType', \n",
    "#                 'sum', 'seqLen', 'entity_cnt', 'posCnt', 'negCnt']\n",
    "featureNames = [ 'province', 'city', 'deviceType', 'itemId', 'Hour', 'seqLen', 'entity_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "409593e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集+测试集总长=5656022\n",
      "sampleId            4233804\n",
      "label                     2\n",
      "pvId                 400031\n",
      "suv                  354976\n",
      "itemId                 3319\n",
      "logTs               2816572\n",
      "operator                469\n",
      "browserType              31\n",
      "deviceType                4\n",
      "osType                   12\n",
      "province                 36\n",
      "city                    337\n",
      "time                2816572\n",
      "Hour                     24\n",
      "Min                    1440\n",
      "seq                  329228\n",
      "sum                     125\n",
      "mean                     80\n",
      "std                      76\n",
      "nor_sum               15024\n",
      "nor_mean               3566\n",
      "nor_std                6490\n",
      "posCnt                  499\n",
      "negCnt                  761\n",
      "historyCnt             1573\n",
      "allCnt                 1056\n",
      "entity_cnt               24\n",
      "mean_emotion_gap      19574\n",
      "seqLen                   21\n",
      "testSampleId        1422218\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5656022/5656022 [04:02<00:00, 23308.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item词典大小=107835\n",
      "实体词典大小=241319\n",
      "特征词典总大小=350310\n"
     ]
    }
   ],
   "source": [
    "def generate_vocab(featureList):\n",
    "    \n",
    "    featureDic = dict()\n",
    "    entityCounter = Counter()\n",
    "    itemCounter = Counter()\n",
    "    featureDic['[sep]'] = 0\n",
    "    featureDic['[noHistory]'] = 1\n",
    "    idx = 2\n",
    "    for i in [-2,-1,0,1,2]:\n",
    "        featureDic[f'emotion_{i}'] = idx\n",
    "        idx += 1\n",
    "    for i in range(600):\n",
    "        featureDic[f'timeGap_{i}s'] = idx\n",
    "        idx += 1\n",
    "    featureDic[f'timeGap_MoreThan10min'] = idx\n",
    "    idx += 1\n",
    "    for i in range(0,100):\n",
    "        featureDic[f'timeGap_{i}h'] = idx\n",
    "        idx += 1\n",
    "    featureDic[f'timeGap_MoreThan100h'] = idx\n",
    "    idx += 1\n",
    "    featureDic[f'timeGap_LessThan0h'] = idx\n",
    "    idx += 1\n",
    "    feature = pd.concat(featureList,axis=0)\n",
    "    print(f'训练集+测试集总长={len(feature)}')\n",
    "    print(feature.nunique())\n",
    "    \n",
    "    for name in featureNames:\n",
    "        if name=='itemId': \n",
    "            for itemId in feature[name].unique():\n",
    "                itemCounter[itemId] += 1\n",
    "                for entity in entity_map[itemId]:\n",
    "                    entityCounter[entity] += 1\n",
    "        else:\n",
    "            for each in feature[name].unique():\n",
    "                featureDic[f'{name}_{each}'] = idx\n",
    "                idx += 1\n",
    "    for seqArr in tqdm(feature['seq']):\n",
    "        if len(seqArr) == 1:  # 无历史信息\n",
    "            continue\n",
    "        seqArr = json.loads(seqArr.replace('\\'', '\\\"'))\n",
    "        assert len(seqArr)%2 == 0\n",
    "        for i in range(0,len(seqArr),2):\n",
    "            time = int(seqArr[i+1])\n",
    "            itemId = int(seqArr[i])\n",
    "            itemCounter[itemId] += 1\n",
    "            for entity in entity_map[itemId]:\n",
    "                entityCounter[entity] += 1\n",
    "    \n",
    "    print(f'item词典大小={len(itemCounter)}')\n",
    "    for i,itemId in enumerate(itemCounter):\n",
    "        featureDic[f'itemId_{itemId}'] = idx\n",
    "        idx += 1\n",
    "    \n",
    "    print(f'实体词典大小={len(entityCounter)}')\n",
    "    for i,entity in enumerate(entityCounter):\n",
    "        assert entity not in featureDic\n",
    "        featureDic[entity] = idx\n",
    "        idx += 1\n",
    "        \n",
    "    print(f'特征词典总大小={len(featureDic)}') \n",
    "    return featureDic\n",
    "#     print(featureDic)\n",
    "#     print(len(entityCounter),entityCounter) \n",
    "featureDic = generate_vocab([train_feature, test_feature])\n",
    "with open('./data/feature/featureDic.json', 'w') as f:\n",
    "    json.dump(featureDic,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f89beed",
   "metadata": {},
   "source": [
    "#### group时间间隔统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4c4275c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299919/299919 [02:16<00:00, 2199.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    299919.0\n",
       "mean        587.0\n",
       "std           0.0\n",
       "min         587.0\n",
       "25%         587.0\n",
       "50%         587.0\n",
       "75%         587.0\n",
       "max         587.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group = train_feature.groupby('pvId')\n",
    "timeGap = []\n",
    "historyGap = []\n",
    "for group in tqdm(feature_group):\n",
    "    firstTime = group_df['logTs'].min()\n",
    "    timeGap.append(int((group_df['logTs'].max()-firstTime)/1000))\n",
    "    for seqArr in group[1]['seq']:\n",
    "        if len(seqArr) == 1:  # 无历史信息\n",
    "            continue\n",
    "        seqArr = json.loads(seqArr.replace('\\'', '\\\"'))\n",
    "        assert len(seqArr)%2 == 0\n",
    "        for i in range(0,len(seqArr),2):\n",
    "            time = int(seqArr[i+1])\n",
    "#             assert firstTime > time\n",
    "            historyGap.append(int((firstTime - time)/1000/3600))\n",
    "timeGap = pd.Series(timeGap)\n",
    "timeGap.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "666b06e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6.314284e+07\n",
       "mean     3.921326e+01\n",
       "std      4.413392e+01\n",
       "min     -2.600000e+01\n",
       "25%      8.000000e+00\n",
       "50%      3.200000e+01\n",
       "75%      5.800000e+01\n",
       "max      1.621000e+03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historyGap = pd.Series(historyGap)\n",
    "historyGap.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ebc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,120,24):\n",
    "    print(f'历史浏览时间间隔小于{i}h\\t'len(historyGap[historyGap<=i])/len(historyGap))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40f01be",
   "metadata": {},
   "source": [
    "#### 生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3998877c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299919/299919 [10:32<00:00, 474.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    247082.000000\n",
       "mean        130.839041\n",
       "std          21.938947\n",
       "min          14.000000\n",
       "25%         119.000000\n",
       "50%         144.000000\n",
       "75%         144.000000\n",
       "max        1754.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/feature/featureDic.json') as f:\n",
    "    featureDic = json.load(f)\n",
    "\n",
    "feature_group = train_feature.groupby('pvId')\n",
    "lengths = []\n",
    "train_df = []\n",
    "for group in tqdm(feature_group):\n",
    "    group_df = group[1].sort_values(by = 'logTs')  # 按时间顺序排序\n",
    "#     group_df['time'] = pd.to_datetime(group_df['logTs'],unit='ms',origin=pd.to_datetime('1970-01-01 08:00:00'))\n",
    "#     print(group_df[featureNames+['logTs', 'time']])\n",
    "    \n",
    "#     userFeatures = ['province', 'city', 'deviceType', 'seqLen']\n",
    "#     for each in userFeatures:\n",
    "#         assert len(group_df[each].unique()==1)\n",
    "        \n",
    "    x, y = [], []\n",
    "    '''\n",
    "    user 特征 (只添加一次)\n",
    "    '''\n",
    "    for item in group_df[featureNames].itertuples():\n",
    "        x.append(featureDic['[sep]'])\n",
    "        x.append(featureDic[f'province_{item.province}'])\n",
    "        x.append(featureDic[f'city_{item.city}'])\n",
    "        x.append(featureDic[f'deviceType_{item.deviceType}'])\n",
    "        x.append(featureDic[f'seqLen_{item.seqLen}'])           # 历史记录长度\n",
    "        x.append(featureDic['[sep]'])        \n",
    "        \n",
    "        y.extend([2] * len(x))\n",
    "        break\n",
    "    firstTime = 0\n",
    "    \n",
    "    '''\n",
    "    文章特征\n",
    "    '''\n",
    "    for idx, item in enumerate(group_df[featureNames+['label', 'logTs']].itertuples()):\n",
    "        if idx == 0:\n",
    "            firstTime = int(item.logTs)\n",
    "        x.append(featureDic[f'itemId_{item.itemId}'])\n",
    "        x.append(featureDic[f'Hour_{item.Hour}'])\n",
    "        x.append(featureDic[f'entity_cnt_{item.entity_cnt}'])   # 共现实体数（加权）\n",
    "        \n",
    "        gap = int(abs(int(item.logTs)-firstTime)/1000) # 距离第一篇文章时间间隔（秒）\n",
    "        if gap <= 599:\n",
    "            x.append(featureDic[f'timeGap_{gap}s'])\n",
    "        else:\n",
    "            x.append(featureDic['timeGap_MoreThan10min'])\n",
    "        x.append(featureDic['[sep]'])\n",
    "        \n",
    "        y.extend([item.label]*5)\n",
    "    assert len(x) == len(y)\n",
    "#     print(len(x))\n",
    "    '''\n",
    "    历史特征 (只添加一次)\n",
    "    '''\n",
    "    seqArr = group_df['seq'].values[0]\n",
    "    if len(seqArr) == 1:  # 无历史信息\n",
    "        x.append(featureDic['[noHistory]'])\n",
    "        x.append(featureDic['[sep]'])\n",
    "        y.extend([3, 3])\n",
    "        continue\n",
    "    seqArr = json.loads(seqArr.replace('\\'', '\\\"'))\n",
    "    assert len(seqArr)%2 == 0\n",
    "    historyPair = []\n",
    "    for i in range(0,len(seqArr),2):\n",
    "        time = int(seqArr[i+1])\n",
    "        itemId = int(seqArr[i])\n",
    "        historyPair.append([itemId, time])\n",
    "    historyPair = sorted(historyPair,key=lambda x:-x[1]) # 按时间排序离当前时间近的排前面\n",
    "#         pprint(historyPair)\n",
    "    for itemId, time in historyPair:\n",
    "        historyTimeGap = int((firstTime - time)/1000/3600)\n",
    "        if historyTimeGap<0:\n",
    "            key = 'timeGap_LessThan0h'\n",
    "        elif historyTimeGap>=100:\n",
    "            key = 'timeGap_MoreThan100h'\n",
    "        else:\n",
    "            key = f'timeGap_{historyTimeGap}h'\n",
    "\n",
    "        x.append(featureDic[f'itemId_{item.itemId}'])\n",
    "        x.append(featureDic[key])\n",
    "        x.append(featureDic['[sep]'])\n",
    "        y.extend([3, 3, 3])\n",
    "#     print(len(x), x)\n",
    "#     print(len(y), y)\n",
    "    assert len(x) == len(y)\n",
    "    lengths.append(len(x))\n",
    "    train_df.append([x,y])\n",
    "#     break\n",
    "train_df = pd.DataFrame(train_df)\n",
    "lengths = pd.Series(lengths)\n",
    "lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3843755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 711, 747, 1083, 1130, 0, 2863, 1103, 1132,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 710, 746, 1083, 1111, 0, 1156, 1087, 1132,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 711, 747, 1083, 1112, 0, 1171, 1088, 1136,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 711, 747, 1083, 1111, 0, 2103, 1098, 1135,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 711, 747, 1083, 1111, 0, 1194, 1090, 1133,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247077</th>\n",
       "      <td>[0, 717, 785, 1083, 1111, 0, 2139, 1110, 1132,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247078</th>\n",
       "      <td>[0, 723, 992, 1083, 1111, 0, 3435, 1110, 1132,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247079</th>\n",
       "      <td>[0, 711, 747, 1083, 1125, 0, 2139, 1110, 1132,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247080</th>\n",
       "      <td>[0, 720, 757, 1083, 1111, 0, 1187, 1107, 1133,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247081</th>\n",
       "      <td>[0, 711, 747, 1083, 1111, 0, 3162, 1110, 1132,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247082 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      ids  \\\n",
       "0       [0, 711, 747, 1083, 1130, 0, 2863, 1103, 1132,...   \n",
       "1       [0, 710, 746, 1083, 1111, 0, 1156, 1087, 1132,...   \n",
       "2       [0, 711, 747, 1083, 1112, 0, 1171, 1088, 1136,...   \n",
       "3       [0, 711, 747, 1083, 1111, 0, 2103, 1098, 1135,...   \n",
       "4       [0, 711, 747, 1083, 1111, 0, 1194, 1090, 1133,...   \n",
       "...                                                   ...   \n",
       "247077  [0, 717, 785, 1083, 1111, 0, 2139, 1110, 1132,...   \n",
       "247078  [0, 723, 992, 1083, 1111, 0, 3435, 1110, 1132,...   \n",
       "247079  [0, 711, 747, 1083, 1125, 0, 2139, 1110, 1132,...   \n",
       "247080  [0, 720, 757, 1083, 1111, 0, 1187, 1107, 1133,...   \n",
       "247081  [0, 711, 747, 1083, 1111, 0, 3162, 1110, 1132,...   \n",
       "\n",
       "                                                   labels  \n",
       "0       [2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...  \n",
       "1       [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2       [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...  \n",
       "3       [2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...  \n",
       "4       [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "247077  [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "247078  [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "247079  [2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...  \n",
       "247080  [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "247081  [2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...  \n",
       "\n",
       "[247082 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns = ['ids','labels']\n",
    "train_df.to_csv('./data/transformer_train_data.csv',index=False)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73ce64",
   "metadata": {},
   "source": [
    "#### 生成测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6bf6d6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100112/100112 [03:31<00:00, 474.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    82145.000000\n",
       "mean       131.383821\n",
       "std         22.481205\n",
       "min         22.000000\n",
       "25%        120.000000\n",
       "50%        144.000000\n",
       "75%        144.000000\n",
       "max       1329.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group = test_feature.groupby('pvId')\n",
    "lengths = []\n",
    "test_df = []\n",
    "for group in tqdm(feature_group):\n",
    "    group_df = group[1].sort_values(by = 'logTs')  # 按时间顺序排序\n",
    "#     group_df['time'] = pd.to_datetime(group_df['logTs'],unit='ms',origin=pd.to_datetime('1970-01-01 08:00:00'))\n",
    "#     print(group_df[featureNames+['logTs', 'time']])\n",
    "    \n",
    "#     userFeatures = ['province', 'city', 'deviceType', 'seqLen']\n",
    "#     for each in userFeatures:\n",
    "#         assert len(group_df[each].unique()==1)\n",
    "        \n",
    "    x = []\n",
    "    '''\n",
    "    user 特征 (只添加一次)\n",
    "    '''\n",
    "    for item in group_df[featureNames].itertuples():\n",
    "        x.append(featureDic['[sep]'])\n",
    "        x.append(featureDic[f'province_{item.province}'])\n",
    "        x.append(featureDic[f'city_{item.city}'])\n",
    "        x.append(featureDic[f'deviceType_{item.deviceType}'])\n",
    "        x.append(featureDic[f'seqLen_{item.seqLen}'])           # 历史记录长度\n",
    "        x.append(featureDic['[sep]'])        \n",
    "        \n",
    "        break\n",
    "    firstTime = 0\n",
    "    \n",
    "    '''\n",
    "    文章特征\n",
    "    '''\n",
    "    for idx, item in enumerate(group_df[featureNames+['logTs']].itertuples()):\n",
    "        if idx == 0:\n",
    "            firstTime = int(item.logTs)\n",
    "        x.append(featureDic[f'itemId_{item.itemId}'])\n",
    "        x.append(featureDic[f'Hour_{item.Hour}'])\n",
    "        x.append(featureDic[f'entity_cnt_{item.entity_cnt}'])   # 共现实体数（加权）\n",
    "        \n",
    "        gap = int(abs(int(item.logTs)-firstTime)/1000) # 距离第一篇文章时间间隔（秒）\n",
    "        if gap <= 599:\n",
    "            x.append(featureDic[f'timeGap_{gap}s'])\n",
    "        else:\n",
    "            x.append(featureDic['timeGap_MoreThan10min'])\n",
    "        x.append(featureDic['[sep]'])\n",
    "        \n",
    "    '''\n",
    "    历史特征 (只添加一次)\n",
    "    '''\n",
    "    seqArr = group_df['seq'].values[0]\n",
    "    if len(seqArr) == 1:  # 无历史信息\n",
    "        x.append(featureDic['[noHistory]'])\n",
    "        x.append(featureDic['[sep]'])\n",
    "        continue\n",
    "    seqArr = json.loads(seqArr.replace('\\'', '\\\"'))\n",
    "    assert len(seqArr)%2 == 0\n",
    "    historyPair = []\n",
    "    for i in range(0,len(seqArr),2):\n",
    "        time = int(seqArr[i+1])\n",
    "        itemId = int(seqArr[i])\n",
    "        historyPair.append([itemId, time])\n",
    "    historyPair = sorted(historyPair,key=lambda x:-x[1]) # 按时间排序离当前时间近的排前面\n",
    "#         pprint(historyPair)\n",
    "    for itemId, time in historyPair:\n",
    "        historyTimeGap = int((firstTime - time)/1000/3600)\n",
    "        if historyTimeGap<0:\n",
    "            key = 'timeGap_LessThan0h'\n",
    "        elif historyTimeGap>=100:\n",
    "            key = 'timeGap_MoreThan100h'\n",
    "        else:\n",
    "            key = f'timeGap_{historyTimeGap}h'\n",
    "\n",
    "        x.append(featureDic[f'itemId_{item.itemId}'])\n",
    "        x.append(featureDic[key])\n",
    "        x.append(featureDic['[sep]'])\n",
    "#     print(len(x), x)\n",
    "#     print(len(y), y)\n",
    "    lengths.append(len(x))\n",
    "    test_df.append([x])\n",
    "#     break\n",
    "test_df = pd.DataFrame(test_df)\n",
    "lengths = pd.Series(lengths)\n",
    "lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a1e8b67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 720, 779, 1085, 1111, 0, 3344, 1101, 1136,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 720, 814, 1083, 1113, 0, 2139, 1090, 1132,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 737, 800, 1083, 1111, 0, 2893, 1090, 1137,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 738, 805, 1083, 1111, 0, 2139, 1090, 1132,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 720, 779, 1083, 1111, 0, 2139, 1090, 1136,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82140</th>\n",
       "      <td>[0, 734, 787, 1083, 1111, 0, 4292, 1110, 1134,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82141</th>\n",
       "      <td>[0, 711, 747, 1083, 1111, 0, 3784, 1110, 1133,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82142</th>\n",
       "      <td>[0, 720, 757, 1083, 1111, 0, 4194, 1110, 1136,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82143</th>\n",
       "      <td>[0, 724, 902, 1083, 1111, 0, 4339, 1110, 1132,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82144</th>\n",
       "      <td>[0, 738, 805, 1083, 1111, 0, 4399, 1110, 1139,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82145 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     ids\n",
       "0      [0, 720, 779, 1085, 1111, 0, 3344, 1101, 1136,...\n",
       "1      [0, 720, 814, 1083, 1113, 0, 2139, 1090, 1132,...\n",
       "2      [0, 737, 800, 1083, 1111, 0, 2893, 1090, 1137,...\n",
       "3      [0, 738, 805, 1083, 1111, 0, 2139, 1090, 1132,...\n",
       "4      [0, 720, 779, 1083, 1111, 0, 2139, 1090, 1136,...\n",
       "...                                                  ...\n",
       "82140  [0, 734, 787, 1083, 1111, 0, 4292, 1110, 1134,...\n",
       "82141  [0, 711, 747, 1083, 1111, 0, 3784, 1110, 1133,...\n",
       "82142  [0, 720, 757, 1083, 1111, 0, 4194, 1110, 1136,...\n",
       "82143  [0, 724, 902, 1083, 1111, 0, 4339, 1110, 1132,...\n",
       "82144  [0, 738, 805, 1083, 1111, 0, 4399, 1110, 1139,...\n",
       "\n",
       "[82145 rows x 1 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns = ['ids']\n",
    "test_df.to_csv('./data/transformer_test_data.csv',index=False)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65134dbb",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc9f5f0",
   "metadata": {},
   "source": [
    "#### sublayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416f24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-6):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.size = d_model\n",
    "        \n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        \n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm\n",
    "\n",
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "    \n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, v)\n",
    "    return output\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \n",
    "        bs = q.size(0)\n",
    "        \n",
    "        # perform linear operation and split into N heads\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # transpose to get dimensions bs * N * sl * d_model\n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "        \n",
    "\n",
    "        # calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1,2).contiguous()\\\n",
    "        .view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "    \n",
    "        return output\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n",
    "        super().__init__() \n",
    "    \n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd2e46e",
   "metadata": {},
   "source": [
    "#### layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdaa181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
    "        self.ff = FeedForward(d_model, dropout=dropout)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c3b8e",
   "metadata": {},
   "source": [
    "#### embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f073c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 200, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        #add constant to embedding\n",
    "        seq_len = x.size(1)\n",
    "        pe = Variable(self.pe[:,:seq_len], requires_grad=False)\n",
    "        if x.is_cuda:\n",
    "            pe.cuda()\n",
    "        x = x + pe\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfab943",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50900d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, max_seq_len=CFG.maxLen, dropout=dropout)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)\n",
    "        self.norm = Norm(d_model)\n",
    "        self.linear = nn.Linear(d_model, 5) # 0,1(点击目标)  2(用户特征)  3(历史特征) 4(pad符号)\n",
    "    def forward(self, src, mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        output = self.linear(self.norm(x))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00cfd96",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d0f261",
   "metadata": {},
   "source": [
    "#### 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1a69b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    maxLen = 300\n",
    "    embedDim = 128\n",
    "    layers = 6\n",
    "    heads = 8\n",
    "    \n",
    "    lr = 1e-4\n",
    "    epoch = 10\n",
    "    batchSize = 64\n",
    "    dropout = 0.1\n",
    "    numWorkers = 4\n",
    "    device = '0'\n",
    "    \n",
    "    split = 0.95\n",
    "    saved_path = './tmp'\n",
    "    \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = CFG.device\n",
    "# CFG.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CFG.device = torch.device(\"cpu\")\n",
    "\n",
    "if not os.path.exists(CFG.saved_path):\n",
    "    os.mkdir(CFG.saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "505e89be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词表大小 350310\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 711, 747, 1083, 1130, 0, 2863, 1103, 1132,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 710, 746, 1083, 1111, 0, 1156, 1087, 1132,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 711, 747, 1083, 1112, 0, 1171, 1088, 1136,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 711, 747, 1083, 1111, 0, 2103, 1098, 1135,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 711, 747, 1083, 1111, 0, 1194, 1090, 1133,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247077</th>\n",
       "      <td>[0, 717, 785, 1083, 1111, 0, 2139, 1110, 1132,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247078</th>\n",
       "      <td>[0, 723, 992, 1083, 1111, 0, 3435, 1110, 1132,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247079</th>\n",
       "      <td>[0, 711, 747, 1083, 1125, 0, 2139, 1110, 1132,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247080</th>\n",
       "      <td>[0, 720, 757, 1083, 1111, 0, 1187, 1107, 1133,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247081</th>\n",
       "      <td>[0, 711, 747, 1083, 1111, 0, 3162, 1110, 1132,...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247082 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      ids  \\\n",
       "0       [0, 711, 747, 1083, 1130, 0, 2863, 1103, 1132,...   \n",
       "1       [0, 710, 746, 1083, 1111, 0, 1156, 1087, 1132,...   \n",
       "2       [0, 711, 747, 1083, 1112, 0, 1171, 1088, 1136,...   \n",
       "3       [0, 711, 747, 1083, 1111, 0, 2103, 1098, 1135,...   \n",
       "4       [0, 711, 747, 1083, 1111, 0, 1194, 1090, 1133,...   \n",
       "...                                                   ...   \n",
       "247077  [0, 717, 785, 1083, 1111, 0, 2139, 1110, 1132,...   \n",
       "247078  [0, 723, 992, 1083, 1111, 0, 3435, 1110, 1132,...   \n",
       "247079  [0, 711, 747, 1083, 1125, 0, 2139, 1110, 1132,...   \n",
       "247080  [0, 720, 757, 1083, 1111, 0, 1187, 1107, 1133,...   \n",
       "247081  [0, 711, 747, 1083, 1111, 0, 3162, 1110, 1132,...   \n",
       "\n",
       "                                                   labels  \n",
       "0       [2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...  \n",
       "1       [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2       [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...  \n",
       "3       [2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...  \n",
       "4       [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "247077  [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "247078  [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "247079  [2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...  \n",
       "247080  [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "247081  [2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...  \n",
       "\n",
       "[247082 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/feature/featureDic.json') as f:\n",
    "    vocab = json.load(f)\n",
    "print('词表大小',len(vocab))\n",
    "train_df = pd.read_csv('./data/transformer_train_data.csv')\n",
    "test_df = pd.read_csv('./data/transformer_test_data.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fbb68f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, vocab, maxLen):\n",
    "        self.ids = df['ids'].values\n",
    "        self.labels = df['labels'].values\n",
    "        self.maxLen = maxLen\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def prepare_input(self, ids, labels):\n",
    "        assert len(ids) == len(labels)\n",
    "        if len(ids)>=self.maxLen:\n",
    "            ids = ids[:self.maxLen-1] + [vocab['[sep]']]\n",
    "            labels = labels[:self.maxLen-1] + [2]\n",
    "            masks = [1] * self.maxLen\n",
    "        else:\n",
    "            padLen = self.maxLen - len(ids)\n",
    "            ids = ids + [vocab['[sep]']] * padLen\n",
    "            labels = labels + [4] * padLen   # label pad = 4\n",
    "            masks = [1] * (self.maxLen-padLen)+ [0] * padLen\n",
    "#         print(len(ids) , len(labels) ,len(masks))\n",
    "        assert len(ids) == len(labels) ==len(masks)\n",
    "        ids = torch.LongTensor(ids)\n",
    "        masks = torch.BoolTensor(masks)\n",
    "        labels = torch.LongTensor(labels)\n",
    "        return ids,masks,labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        temp_id = json.loads(self.ids[idx])\n",
    "        temp_label = json.loads(self.labels[idx])\n",
    "        ids,masks,labels = self.prepare_input(temp_id, temp_label)\n",
    "        \n",
    "        return ids,masks,labels\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, vocab, maxLen):\n",
    "        self.ids = df['ids'].values\n",
    "        self.maxLen = maxLen\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def prepare_input(self, ids, labels):\n",
    "        if len(ids)>=self.maxLen:\n",
    "            ids = ids[:self.maxLen-1] + [vocab['[sep]']]\n",
    "            masks = [1] * self.maxLen\n",
    "        else:\n",
    "            padLen = self.maxLen - len(ids)\n",
    "            ids = ids + [vocab['[sep]']] * padLen\n",
    "            masks = [1] * len(ids) + [0] * padLen\n",
    "        assert len(ids) == len(labels) ==len(masks)\n",
    "        ids = torch.LongTensor(ids)\n",
    "        masks = torch.BoolTensor(masks)\n",
    "        return ids,masks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ids,masks = self.prepare_input(self.ids[idx], self.labels[idx])\n",
    "        return ids,masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cb42e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据量: 234728 12354 82145\n",
      "batch数: 3667 193 1284\n"
     ]
    }
   ],
   "source": [
    "train = train_df.sample(frac=CFG.split) #按0.6比例随机采样\n",
    "valid=train_df[~train_df.index.isin(train.index)]\n",
    "\n",
    "train_dataset = TrainDataset(train, vocab, CFG.maxLen)\n",
    "valid_dataset = TrainDataset(valid, vocab, CFG.maxLen)\n",
    "test_dataset = TestDataset(test_df, vocab, CFG.maxLen)\n",
    "print('数据量:', len(train_dataset), len(valid_dataset), len(test_dataset))\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batchSize,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.numWorkers, pin_memory=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batchSize,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.numWorkers, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=CFG.batchSize,\n",
    "                          shuffle=False,\n",
    "                          num_workers=CFG.numWorkers, pin_memory=True, drop_last=False)\n",
    "print('batch数:', len(train_loader), len(valid_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084007d",
   "metadata": {},
   "source": [
    "#### 主程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eae7028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] EPOCH = 00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3667 [00:31<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22094/1598990638.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.cuda(device=CFG.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;31m#.cuda(device=CFG.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_size, embed_dim, 4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fnc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22094/1598990638.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.cuda(device=CFG.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mbatch_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepctr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22094/3169202407.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepctr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22094/1497217716.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepctr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22094/1150449155.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# calculate attention using function we will define next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;31m# concatenate heads and put through final linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mconcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22094/1150449155.py\u001b[0m in \u001b[0;36mattention\u001b[0;34m(q, k, v, d_k, mask, dropout)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m  \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Encoder(len(vocab), CFG.embedDim, CFG.layers, CFG.heads, CFG.dropout)\n",
    "# model = model.cuda(device=CFG.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "loss_fnc = nn.CrossEntropyLoss(weight=torch.from_numpy(np.array([1, 5, 0.5, 0.5,0.1])).float() ,\n",
    "                                        size_average=True)#.cuda()\n",
    " # 0,1(点击目标)  2(用户特征)  3(历史特征) 4(pad符号)\n",
    "def eval(model):\n",
    "    model.eval()\n",
    "    x, y = [], []\n",
    "    for step, (ids, masks, labels) in enumerate(valid_loader):\n",
    "        ids = ids#.cuda(device=CFG.device)\n",
    "        masks = masks.unsqueeze(-2)#.cuda(device=CFG.device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(ids, masks)\n",
    "        batch_pred = logits.detach().cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        ids = ids.cpu().numpy()\n",
    "        \n",
    "        for idx, pred_logits in enumerate(batch_pred):\n",
    "            label = labels[idx]    \n",
    "#             print(np.sum(label==0), np.sum(label==1))\n",
    "            for i in range(2):\n",
    "                ind = np.where(label==i)\n",
    "                logits = pred_logits[ind]   # [标签数, 4] \n",
    "                logits = logits[:,:2 ]      # [标签数, 2] \n",
    "                logits = softmax(logits, axis=-1).argmax(-1)\n",
    "                if len(logits):\n",
    "                    truth = label[ind]\n",
    "#                     x.extend(logits[:,1:].ravel().tolist())\n",
    "                    x.extend(logits.ravel().tolist())\n",
    "#                     print('111111', i, np.sum(truth==0), np.sum(truth==1), truth)\n",
    "                    y.extend(truth.tolist())\n",
    "#         sys.exit()\n",
    "    print(f'truth为1个数={np.sum(np.array(y)==1)}\\tpred为1个数={np.sum(np.array(x)==1)}')\n",
    "    print(f'truth为0个数={np.sum(np.array(y)==0)}\\tpred为1个数={np.sum(np.array(x)==0)}')\n",
    "    return roc_auc_score(y,x), f1_score(y,x)\n",
    "        \n",
    "best_score = 0\n",
    "step_num = len(train_loader)\n",
    "for epoch in range(5):\n",
    "    totol_loss = 0\n",
    "    print('[Training] EPOCH = {:02d} '.format(epoch))\n",
    "    tk0=tqdm(enumerate(train_loader), total=step_num)\n",
    "    for i, (ids, masks, labels) in tk0:\n",
    "        model.train()\n",
    "        ids = ids#.cuda(device=CFG.device)\n",
    "        masks = masks.unsqueeze(-2)#.cuda(device=CFG.device)\n",
    "        labels = labels#.cuda(device=CFG.device)\n",
    "        logits = model(ids, masks) # [batch_size, embed_dim, 4]\n",
    "        loss = loss_fnc(logits.permute(0, 2, 1), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        totol_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % int(step_num/4) == 0:\n",
    "            auc,f1 = eval(model)\n",
    "            print('[EVAL] epoch={:02d}\\tstep={:03d}\\taucScore={:.3f}\\tf1Score={:.3f}'.format(epoch,i,auc,f1))\n",
    "            if auc > best_score:\n",
    "                best_score = auc\n",
    "                torch.save(model, os.path.join(CFG.saved_path,'model.pth'))\n",
    "                print('best score:', best_score)\n",
    "#             print('epoch={:02d}\\tstep={:03d}\\tloss={:.3f}'.format(epoch,i,loss.item()))\n",
    "        tk0.set_postfix(Epoch=epoch, Step=i, Loss=totol_loss/(i+1))\n",
    "#         break\n",
    "#     break    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c16ff",
   "metadata": {},
   "source": [
    "#### 输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7193ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201cd37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepctr",
   "language": "python",
   "name": "deepctr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
